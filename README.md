# North Indian Food Menu Suggester

An intelligent AI-powered food menu system using **multi-agent cognitive architecture**, **Model Context Protocol (MCP)**, and **Gemini 2.0 Flash**.

## 🎯 The Problem

Every household faces this daily: "What should we cook?" This simple question takes 10-15 minutes of thinking every single time!

## 💡 The Solution

An AI agent system that:
- ✅ Understands your preferences (taste, cooking style, ingredients)
- ✅ Considers time constraints (quick vs elaborate meals)
- ✅ Avoids repetition by checking meal history
- ✅ Generates complete, detailed North Indian menus
- ✅ Provides cooking times, difficulty levels, and chef's notes

## 🏗️ Architecture

### Multi-Agent Cognitive System

1. **main.py** - Orchestrator with MCP client
2. **perception.py** - Question generation & fact extraction (Pydantic)
3. **memory.py** - Preference storage (Pydantic)
4. **decision.py** - LLM-driven decision making with full autonomy
5. **actions.py** - MCP Server with intelligent tools
6. **models.py** - Pydantic data models

### Key Design Principles

🤖 **LLM-Driven Workflow** - Gemini decides which tools to call and when (no prescribed workflow)
🔧 **Proper MCP Implementation** - Actions run as MCP server with stdio communication
📊 **Pydantic Models** - Structured, validated data flow
🔄 **Feedback Loop** - Decision layer iterates until satisfied
🎨 **No Hardcoded Menus** - All dishes generated by LLM based on context

## 🛠️ MCP Tools

The Actions layer provides 5 essential tools:

| Tool | Purpose | Parameters |
|------|---------|------------|
| `check_calendar` | Get current date/day/time | None |
| `get_meal_history` | Retrieve recent meals | `days` (default: 7) |
| `get_user_preferences` | Get taste/style preferences | None |
| `generate_final_menu` | **LLM-powered menu generation** | `context_json` |
| `save_meal_to_history` | Store meal records | `meal_data_json` |

### 🌟 Key Tool: generate_final_menu

This tool uses **Gemini LLM** to create complete menus:
- Takes all context (preferences, constraints, history)
- Uses Gemini's knowledge of North Indian cuisine
- Generates specific dishes with descriptions
- Includes cooking times, difficulty, ingredients
- Adds chef's notes for context
- **NO hardcoded dishes anywhere**

## 📦 Installation

### Prerequisites
- Python 3.10+
- Gemini API key ([Get one here](https://aistudio.google.com/app/apikey))

### Setup

1. **Clone the repository**
```bash
git clone <your-repo-url>
cd food-menu
```

2. **Install dependencies**
```bash
# Using uv (recommended)
uv sync

# Or using pip
pip install -r requirements.txt
```

3. **Set up API key**

Create a `.env` file:
```bash
echo "GEMINI_API_KEY=your-api-key-here" > .env
```

Or export it:
```bash
export GEMINI_API_KEY='your-api-key-here'
```

4. **Run the application**
```bash
python main.py
```

## 🚀 Usage

### Example Session

```
📝 What would you like to eat?
Your query: suggest something for dinner which can be cooked quickly

💬 Please answer the following questions:
1. How many people will be eating?
> 2

2. How much time do you have for cooking?
> 30 minutes

3. Any dietary restrictions?
> vegetarian

🔄 Starting Decision-Action Loop...

🎯 DECISION LAYER (Iteration 1):
   Calling: get_user_preferences

🎯 DECISION LAYER (Iteration 2):
   Calling: get_meal_history

🎯 DECISION LAYER (Iteration 3):
   Calling: generate_final_menu

🎉 FINAL RESULT:
🍽️ DINNER MENU

🍛 Main Dishes:
• Aloo Matar - Potato and peas curry with aromatic spices (30 min, Easy)
  Ingredients: Potatoes, peas, tomatoes, onions, spices
• Bhindi Masala - Crispy okra stir-fried with onions and spices (25 min, Easy)
  Ingredients: Okra, onions, tomatoes, spices

🥗 Side Dishes:
• Roti - Whole wheat flatbread, soft and warm (20 min, Easy)
  Ingredients: Wheat flour, water, ghee

☕ Beverage:
• Masala Chai - Traditional spiced tea with cardamom and ginger (10 min, Easy)
  Ingredients: Tea leaves, milk, sugar, cardamom, ginger

⏱️ Total Time: 45 minutes
👥 Serves: 2 people

💡 Chef's Note:
This menu is perfect for a quick weeknight dinner. The mild Aloo Matar balances 
the slightly tangy Bhindi Masala. Both dishes are easy to prepare and use common 
pantry ingredients. The meal is complete with fresh rotis and aromatic chai.
```

## 🎓 How It Works

### Flow Diagram

```
User Query
    ↓
Perception Layer
  • Generates clarifying questions
  • Collects user responses
  • Extracts facts → ExtractedFacts (Pydantic)
    ↓
Memory Layer
  • Retrieves preferences → UserPreferences (Pydantic)
  • Default: taste=spicy, style=modern, ingredients=[wheat, pulses, rice]
    ↓
MCP Connection
  • Establishes stdio connection to actions.py MCP server
    ↓
┌─────────────────────────────────────────────────┐
│  Decision-Action Loop (LLM has full autonomy)   │
│                                                 │
│  Iteration 1:                                   │
│    LLM → FUNCTION_CALL: get_user_preferences    │
│    Execute → Result                             │
│                                                 │
│  Iteration 2:                                   │
│    LLM → FUNCTION_CALL: get_meal_history|7      │
│    Execute → Result                             │
│                                                 │
│  Iteration 3:                                   │
│    LLM → FUNCTION_CALL: generate_final_menu|... │
│    Execute → Complete menu generated            │
│                                                 │
│  Iteration 4:                                   │
│    LLM → FINAL_ANSWER: [complete menu]          │
│    DONE ✅                                      │
└─────────────────────────────────────────────────┘
    ↓
Display Final Menu
```

### LLM Autonomy

The Decision Layer has **full autonomy**:
- Decides which tools to call
- Decides the order of tool calls
- Decides when it has enough information
- Decides when to provide final answer

**No prescribed workflow** - LLM adapts to query complexity!

## 📂 Project Structure

```
food-menu/
├── main.py                 # Orchestrator with MCP client
├── perception.py           # Question generation & fact extraction
├── memory.py               # Preference storage
├── decision.py             # LLM-driven decision making
├── actions.py              # MCP Server with tools
├── models.py               # Pydantic data models
├── requirements.txt        # Python dependencies
├── pyproject.toml          # Project configuration
├── .env                    # Environment variables (API key)
├── user_preferences.json   # Stored preferences (auto-created)
└── README.md
```

## 🔧 Configuration

### User Preferences

Edit `user_preferences.json` (auto-created on first run):

```json
{
  "taste": "spicy",
  "food_style": "modern",
  "ingredients": ["wheat flour", "pulses", "rice"],
  "dietary_type": "vegetarian",
  "avoid_ingredients": [],
  "meal_history": []
}
```

### Customization Options

- **Taste**: spicy, mild, medium
- **Food Style**: traditional, modern, fusion
- **Ingredients**: List of preferred ingredients
- **Dietary Type**: vegetarian, vegan, non-vegetarian
- **Avoid Ingredients**: List of ingredients to exclude

## 🧪 Testing

Test the MCP server independently:

```bash
python test_mcp.py
```

This will test all MCP tools and verify the connection.

## 📚 Technical Details

### Dependencies

```
google-generativeai>=0.3.0  # Gemini 2.0 Flash
mcp>=0.9.0                  # Model Context Protocol
pydantic>=2.0.0             # Data validation
fastmcp>=0.1.0              # FastMCP for easy MCP server
python-dotenv>=1.0.0        # Environment variable loading
```

### MCP Architecture

- **Server**: `actions.py` runs as stdio MCP server using FastMCP
- **Client**: `main.py` connects via `stdio_client`
- **Communication**: JSON-RPC over stdio
- **Tools**: Registered with `@mcp.tool()` decorator
- **Process**: Child process spawned by main.py

### Pydantic Integration

All data flows through validated Pydantic models:
- `ExtractedFacts` - User requirements
- `UserPreferences` - Memory preferences
- Type safety across all layers
- Automatic validation and serialization

### LLM Integration

- **Model**: Gemini 2.0 Flash Experimental
- **Mode**: JSON output for structured responses
- **Pattern**: FUNCTION_CALL or FINAL_ANSWER
- **Autonomy**: LLM decides workflow dynamically

## 🎯 Use Cases

- Daily meal planning
- Recipe suggestions based on preferences
- Time-constrained cooking
- Dietary restriction management
- Meal variety tracking
- Avoiding repetitive meals

## 🚧 Troubleshooting

### API Key Issues

If you see "GEMINI_API_KEY not set":
1. Check `.env` file exists and has the key
2. Or export it: `export GEMINI_API_KEY='your-key'`
3. Restart the application

### MCP Connection Issues

If MCP server fails to start:
1. Check Python version (3.10+ required)
2. Verify all dependencies installed: `uv sync`
3. Test MCP server: `python test_mcp.py`

### Short Menu Output

If menu is incomplete:
- Check API key is valid
- Verify internet connection
- Check Gemini API quota

## 🤝 Contributing

Contributions welcome! Areas for improvement:
- Add more cuisines (South Indian, Chinese, etc.)
- Integrate with recipe databases
- Add nutritional information
- Support for meal planning (weekly menus)
- Integration with grocery lists
- Voice interface

## 📄 License

MIT License - Feel free to use and modify!

## 🙏 Credits

- **Gemini 2.0 Flash** by Google
- **MCP** by Anthropic
- **FastMCP** by James Lowin
- **Pydantic** by Samuel Colvin

## 📞 Support

For issues or questions:
- Open an issue on GitHub
- Check existing documentation
- Review the code comments

---

**Built with ❤️ using AI agents and MCP**

**Star ⭐ this repo if you find it useful!**
